---
title: "Bristol's Air Quality in the COVID-19 Lockdown"
author: "Steve Crawshaw"
date: "April 2020"
output: html_document
fig_caption: yes
editor_options: 
  chunk_output_type: console
---
This brief report summarises the air quality impact of the lockdown policy on air quality measurements in Bristol. 

```{r Load libraries, eval = TRUE, include = FALSE}
#-----------------------------------LIBRARIES-----------------------------------
wants <- c("tidyverse", "data.table", "DT", "openair", "here", "lubridate", "deweather", "httr", "jsonlite", "ggeasy", "zoo")
has   <- wants %in% rownames(installed.packages())
if(any(!has)) install.packages(wants[!has])
lapply(wants, library, character.only=T)

```

```{r Set variables, eval = TRUE, include = FALSE}
#---------------------------------VARIABLES-------------------------------------
Sys.setenv(TZ = "Etc/GMT-0")
dateFrom = "2017-12-31" # for analysis of raw data
rawdata_startDate_chr <- "2018-12-31"
rawdata_startDate <- as.Date(rawdata_startDate_chr)
studyStartDate_chr <- "2020-03-01"
studyStartDate <- as.Date(studyStartDate_chr)
studyStartDate_julian = yday(studyStartDate)
dateFrom_dw <- "2020-01-01" #start of deweather analysis period
dateTo = "2020-04-30" #final day of lockdown period (or latest date for monitoring data)
lockdown_start_date_chr <- "2020-03-24" #announced 23/03/2020

startDate_2020 <- as.Date(dateFrom_dw)
startdate <- as.Date(dateFrom)
enddate <- as.Date(dateTo)
startDate_dw <- as.Date(dateFrom_dw)
lockdown_start_date <- as.Date(lockdown_start_date_chr)
lockdown_end_date <- as.Date(dateTo)
lockdown_start_julian <- yday(lockdown_start_date)
lockdown_end_julian <- yday(lockdown_end_date)
valid_hours <- as.integer((enddate - startDate_dw) * 24)

ldstart_2019 <- as.Date("2018-12-31") + lockdown_start_julian
ldend_2019 <- as.Date("2018-12-31") + lockdown_end_julian
#data frame for the rectangles to be plotted as geom_rect
rect_df <- data.frame(xmin = c(as.Date("2020-03-16"), lockdown_start_date), xmax = c(lockdown_start_date, enddate), ymin = -Inf, ymax = Inf, fill = c("Social Distancing", "Lockdown")) %>%
  mutate(fill = fct_reorder(as_factor(fill), xmin))

update <- FALSE #is the analysis updating with new data?
#update is used later to set whether data retrieved from online or local data used for speed

# chart_title_date_phrase <- paste0("for period between")
source(here::here("gg_themes.r")) # custom themes for ggplots
```

```{r Download and process continuous, eval = TRUE, include = FALSE}
#--------------------------------CONTINUOUS DATA ODS ---------------------------
if(update){
source(here::here("importODS.r"))
aq_data_DT <- importODSAQ(
    siteid = "all",
    pollutant = c("pm10", "no2", "nox", "no", "o3", "pm25"),
    dateFrom = dateFrom,
    dateTo = dateTo
)
#---------------------------CONTINUOUS DATA AURN--------------------------------
allsites_meta <- importMeta(all = T) %>%
  filter(end_date == "ongoing",
         site_type == "Urban Traffic" |
         site_type == "Urban Background") %>%
  group_by(code) %>%
  summarise(site_type = first(site_type))

core_urb_traff_sites <- c("birr", "br11", "gla4", "led6", "nca3", "nwbv", "shbr", "shlw", "burw")
#
core_raw <- importAURN(site = core_urb_traff_sites, year = 2017:2020, pollutant = "all")
#----------------------------------MET DATA------------------------------
colnames <- c("date_time", "ws", "wd", "temp")
met_data_DT <- fread(paste0("https://opendata.bristol.gov.uk/explore/dataset/met-data-bristol-lulsgate/download/?format=csv&q=date_time:%5B", rawdata_startDate_chr, "T00:00:00Z+TO+", dateTo, "T22:59:59Z%5D&timezone=UTC&lang=en&use_labels_for_header=false&csv_separator=%3B"), select = colnames)
#----------------------------AQ MONITORS META DATA----------------------------
#get site classifications for current sites

keepcols <- c("siteid", "locationclass")
aq_monitors <- fread("https://opendata.bristol.gov.uk/explore/dataset/air-quality-monitoring-sites/download/?format=csv&disjunctive.pollutants=true&refine.current=True&refine.pollutants=NOX&refine.pollutants=PM10&refine.pollutants=PM2.5&refine.pollutants=O3&timezone=Europe/London&lang=en&use_labels_for_header=false&csv_separator=%3B", select = keepcols)

} else {

load(file = here::here("dfs.RData")) #all the data needed for the analysis
}

pm10_am_url <- "https://opendata.bristol.gov.uk/api/v2/catalog/datasets/air-quality-data-continuous/aggregates?select=avg(pm10)%20as%20mean_pm10&group_by=year(date_time)%2C%20siteid&where=date_time%3E%3D'2018'%20AND%20date_time%3C%3D'2018'"
#get annual mean PM10 data from ODS using API V2 and use later in text
pm10_am_data <- pm10_am_url %>% 
  GET() %>% 
  content(as = "text") %>% 
  fromJSON %>% 
  `[[`(2) %>% #get second element of list
  filter(!is.na(mean_pm10))# remove non pm10 sites

pm10_roadside_inc <- (max(pm10_am_data$mean_pm10) - min(pm10_am_data$mean_pm10))/ max(pm10_am_data$mean_pm10) * 100 #percentage of PM10 which is roadside increment - BTW \ AURN

```

```{r data wrangling, eval = TRUE, include = FALSE}
#---------------------------------BCC--------------------------------
lockdown_long <- aq_data_DT %>% 
  filter(date >= rawdata_startDate,
    between(yday(date), lockdown_start_julian, lockdown_end_julian)) %>% 
  mutate(year = as.numeric(format(date, "%Y"))) %>% 
  inner_join(aq_monitors, by = "siteid") %>% 
  pivot_longer(cols = pm10:pm2.5, names_to = "Pollutant", values_to = "Concentration") %>% 
  mutate(Pollutant = as.factor(toupper(Pollutant))) %>% 
  na.omit(cols = "Concentration") %>% 
  mutate(ld_day = yday(date) + 2 - lockdown_start_julian)

lockdown <- lockdown_long %>% 
  mutate(Pollutant = as.factor(tolower(Pollutant))) %>%
  pivot_wider(names_from = Pollutant, values_from = Concentration)

lockdown_roadside <- lockdown %>% 
  filter(locationclass %in% "Urban Traffic") %>% 
  mutate(location = ifelse(location == "Parson Street School", "Parson St.", location)) 
#for chart text fit

#--------------------------------MET DATA-------------------------
met_data_DT_hr <- met_data_DT[, `:=`(date = as.POSIXct(date_time, format = "%Y-%m-%dT%H:%M"), year = as.factor(str_sub(date_time, 1, 4)), date_time = NULL)][, lapply(.SD, mean, na.rm = T), by = .(date = floor_date(date, unit = "hour")), .SDcols = c("temp", "ws", "wd")]
#----------------------------------AURN--------------------------
#calculate means for key pollutants during lockdown period
core_means <- setDT(core_raw)[between(yday(date), lockdown_start_julian, lockdown_end_julian)][,
                            lapply(.SD, mean, na.rm = T),
                            by = .(site, code, year(date)),
                            .SDcols = c("no2", "pm10", "pm2.5"),]

#add the metadata so the DF can be split by site type and rename some sites
core_means_joined <- core_means %>% 
  inner_join(allsites_meta, by = c("code" = "code")) %>% 
  mutate(site = factor(ifelse(code == "BURW", "Manchester", as.character(site))),
         site = factor(ifelse(code == "SHLW", "Liverpool", as.character(site))),
         City := gsub('([A-z]+) .*', '\\1', site)) #extract all before space
#-------------------------GOOGLE TRAFFIC DATA----------------------
mob_url <- "https://opendata.bristol.gov.uk/explore/dataset/google_mobility_data/download/?format=csv&timezone=Europe/London&lang=en&use_labels_for_header=true&csv_separator=%3B"

google_mob_data <- mob_url %>% 
  fread(colClasses = c("Date", "character", "integer")) %>% 
setnames(c("date", "Sector", "pc_change_baseline"))

#-----------------------DE WEATHER WRANGLING------------------------------
#hour average met data, join to AQ data , join to aq_monitors
#add variables for modelling
#strip NA values for no2 and pm10
#filter the sites for data capture rates < 0.9

aq_met_dw_hourly <- aq_data_DT[met_data_DT_hr, on = "date"][aq_monitors, on = "siteid"] %>% 
                        prepData(add = c("hour", "hour.local", "weekday", "trend",
                                     "week", "jday", "month"), local.tz = "Europe/London", lag = NULL) %>% 
  .[, site := as.factor(location)] %>% 
  .[date >= startDate_dw] %>% #only 2020 data
  filter(!is.na(no2) | !is.na(pm10) | !is.na(nox)) %>% #select pollutants
  add_count(site, name = "count") %>% 
  filter(count / valid_hours > 0.9) %>% #View()#remove sites with low data capture
  mutate(site = droplevels(site), 
         locationclass = as.factor(locationclass),
         dw_group = case_when(
           siteid == 501 ~ "City Centre",
           siteid != 501 & locationclass == "Urban Traffic" ~ "Urban Traffic",
           locationclass == "Urban Background" ~ "Urban Background"
         )) #classify sites into 3 classes for intelligible plotting

#aggregate by date and dw_group to give mean hourly values for all pollutants
dw_hourly_agg <- aq_met_dw_hourly %>% 
  group_by(date, dw_group, weekday, month) %>% 
  summarise_if(is.numeric, mean, na.rm = T)

```


```{r summary calcs, eval = TRUE, include = FALSE}

calc_pc_change <- function(df){
  df %>% 
  mutate(`% Change` = (`2020` -`2019`)/`2019` * 100) %>%
  mutate_if(is.numeric, round) %>% 
  filter(Pollutant != "NO")
}

mean_site_table <- lockdown_long %>% 
  group_by(location, Pollutant, year = year(date)) %>%
   summarise(mean_conc = mean(Concentration, na.rm = T)) %>% 
  pivot_wider(id_cols = location:Pollutant, names_from = year, values_from = mean_conc) %>% 
  calc_pc_change()

mean_pollutant_table <- lockdown_long %>% 
  group_by(Pollutant, year = year(date)) %>% 
  summarise(mean_conc = mean(Concentration, na.rm = T)) %>% 
  pivot_wider(id_cols = Pollutant, names_from = year, values_from = mean_conc) %>% 
  calc_pc_change() %>% setDT()

fwrite(mean_pollutant_table, here::here("data", "mean_pollutant_table.csv"))

changeno2 <- mean_pollutant_table[Pollutant == "NO2", `% Change`] #for use in the text
changenox <- mean_pollutant_table[Pollutant == "NOX", `% Change`]
changepm10 <- mean_pollutant_table[Pollutant == "PM10", `% Change`]


```
## Summary
This report summarises changes to ambient air quality, represented by concentrations of regulated pollutants, that have occurred during the COVID-19 lockdown period. The changes in air quality characterised by comparisons of raw data between two periods cannot be solely attributed to the lockdown measures, because weather and other variables strongly influence ambient air quality.

In order to account for the influence of weather and other covariates, a statistical modelling approach has been adopted which can remove the effect of the weather and identify the changes in concentrations which would arise if meteorological conditions and temporal effects are held constant. This approach can be used to ascribe the changes in air quality to lockdown measures with more certainty than simply by comparing raw data between two periods.

The comparison of raw data between 2019 and 2020 was for the period `r ldstart_2019` to `r ldend_2019` and `r lockdown_start_date` to `r lockdown_end_date`.

Analysis of air quality data from Bristol City Council's continuous air monitoring network comparing the lockdown period in 2020 to the same period in 2019 shows a significant change in nitrogen dioxide (NO~2~), a traffic pollutant, of around `r changeno2`%.

Reductions in NOx (oxides of nitrogen), which can be considered a surrogate for direct exhaust emissions, fell even further with a mean change of `r changenox`%. 
Measures of particulate matter (PM) - PM~10~ and PM~2.5~ also fell but the reduction was less. This is because the local contribution to ambient PM is a small part of the total. There are significant regional and background components present which are unaffected by the lockdown measures. For PM~10~ the roadside increment in 2018 was `r round(pm10_roadside_inc)`% when comparing a background and roadside site in the central city.

Ozone (O~3~) rose when compared to the baseline period. This is expected because as NOx declines, less ozone is chemically reduced in the photochemical reaction between these two species and hence concentrations of ozone may rise.

Data from the [NO~2~ diffusion tube network](https://opendata.bristol.gov.uk/explore/dataset/no2-diffusion-tube-data/map/?disjunctive.location&refine.year=2018&location=12,51.46856,-2.60587&basemap=jawg.streets), which gives greater spatial coverage than the continuous network has not been included in this analysis as the measurement period is a calendar month and hence is not suitable for use in this analysis of short term data. BCC are continuing to monitor air quality during lockdown in accordance with government guidance. This includes diffusion tubes, and data from diffusion tubes will be presented in future versions of this report.

All of Bristol's air quality data are available through our [open data portal.](https://opendata.bristol.gov.uk/pages/air-quality-dashboard-new/map#air-quality-now)


## Traffic
Traffic flows started to decline when the first measures were announced on the 16th March. By the time full lockdown was operating (from 24th March), traffic flows had declined by more than 50% compared to normal levels. Data are from BCC's Urban Traffic Control (UTC) system.

```{r Traffic flows, eval = TRUE, echo = FALSE, results = "show", out.width = '100%', fig.width = 14, fig.height = 12, fig.cap = "Fig . Daily traffic flows March 2020"}
knitr::include_graphics(here::here("plots", "traffic_covid_ppt.png"))
```

Google and Apple are providing access to their mobility data during the COVID-19 crisis. The chart below shows smoothed trends in [mobility by sector for Bristol from Google's dataset](https://opendata.bristol.gov.uk/explore/dataset/google_mobility_data/information/). The baseline for comparison is the median value, for the corresponding day of the week, during the 5-week period Jan 3 â€“ Feb 6, 2020. The reduction in mobility for all sectors except residential is apparent. In this context the residential category includes deliveries to homes. There does seem to be a slight increase after the first week in April of non residential sector mobility.

```{r Traffic flows by sector, eval = TRUE, echo = FALSE, results = "show", out.width = '100%', fig.width = 14, fig.height = 12, fig.cap = "Fig . Traffic flows by sector: 2020"}
sector_mobility_plot <- google_mob_data %>%
    mutate(Sector = str_to_title(str_replace_all(Sector, "and", "&"))) %>% 
    ggplot(aes(x = date, y = pc_change_baseline, color = Sector)) +
    geom_smooth(se = F, lwd = 2, method = "loess", formula = 'y ~ x') +
    geom_vline(xintercept = as.Date("2020-03-24"), lty = 5) +
    labs(y = "% change from baseline",
         x = "Date",
        title = "Changes in mobility by sector",
        caption = paste0("Google COVID-19 Community Mobility Reports. \n      https://www.google.com/covid19/mobility/ Accessed: ", Sys.Date())) +
  scale_color_brewer(palette = "Dark2") +
     theme_ppt_single()

sector_mobility_plot

# ggsave(sector_mobility_plot, filename = here::here("plots", "sector_mobility_plot.png"), device = "png", dpi = 200, width = 12, height = 10)


```



## Summary of changes by pollutant

The table below shows the percentage changes in each pollutant aggregated by site between the two lockdown periods.

```{r generate mean pollutant table, eval = TRUE, echo = FALSE, results = "show", out.width = '100%', fig.width = 14, fig.height = 12, fig.cap = "Fig . Average change in pollutant concentrations in ugm-3"}

mean_pollutant_table %>% 
    datatable(rownames = F,
              options = list(dom = 't')) # just the table
```


The table below shows the mean percentage reductions by site and pollutant. Not all sites measure all pollutants.


```{r generate mean site table, eval = TRUE, echo = FALSE, out.width = '100%', fig.width = 14, fig.height = 12, fig.cap = "Fig . Average change in pollutant concentrations by site and pollutant (ugm-3)"}
mean_site_table %>% 
    datatable(rownames = F,
              filter = list(position = "top"),
              options = list(pagelength = 10, language = list(sSearch = "Filter:")))
```


```{r aq map, eval = TRUE, echo = FALSE, out.width = '100%', fig.width = 14, fig.height = 12, fig.cap = "Fig . Locations of current continuous monitoring sites"}
knitr::include_url("https://opendata.bristol.gov.uk/explore/embed/dataset/air-quality-monitoring-sites/map/?disjunctive.pollutants&refine.current=True&refine.instrumenttype=Continuous%20(Reference)&location=12,51.45296,-2.57009&basemap=jawg.streets&static=false&datasetcard=true&scrollWheelZoom=false", height = "400px")
#embed the map of live sites from ODS
```

## Comparison with other cities

The changes in Bristol can be compared with other core cities by using data from the national AURN network. The plot below shows the mean values of NO~2~ for the lockdown period in each of the previous four years. Bristol's national roadside site at Temple Way was not operating in 2017.

```{r data viz National, eval = TRUE, echo = FALSE, warning = FALSE, results = "show", fig.height = 7, fig.width = 11, fig.cap = "Fig . National comparison: nitrogen dioxide"}
#--------------------------------------CORE CITIES-------------------------
city_plot_covid_by_year <- core_means_joined %>% 
  filter(!is.na(no2), site_type == "Urban Traffic") %>% 
  ggplot(aes(x = City, y = no2, fill = as.factor(year))) +
  geom_col(position = "dodge") + 
  scale_y_continuous(quickText("NO2 ug m-3")) +
  labs(title = quickText("Changes in NO2 at core city urban traffic sites in lockdown period"),
       x = "City") +
  labs(fill = "Year") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size=13)) +
  theme_ppt_single() +
  scale_color_brewer(palette = "Dark2") +
  theme(axis.text.x = element_text(angle = 90),
         panel.grid.major = element_blank()) 

ggsave(here::here("plots", "city_plot_covid_by_year.png"), city_plot_covid_by_year, device = "png", width = 10, height = 6, dpi = 200)

city_plot_covid_by_year 

```

## Changes in air quality at Bristol's monitoring sites

Bristol's city centre site at [Colston Avenue](https://opendata.bristol.gov.uk/pages/aqcontinuoussites/?q=siteid:501) is the most polluted roadside site on the network and so is an interesting example of the reductions during the lockdown. The chart below shows weekly mean concentrations of NOx, NO~2~ and PM~10~ for the baseline and lockdown period. Operational issues between 9th April and 15th April mean that data is incomplete for this period.

```{r data viz Colston, eval = TRUE, echo = FALSE, warning = FALSE, results = "show", fig.height = 7, fig.width = 11, fig.cap = "Fig . Chart of Colston Avenue site by pollutant"}
#plot bar chart of means by day, all sites except colston
sites_weekly <- lockdown_long %>% 
  filter(Pollutant %in% c("NOX", "NO2", "PM10")) %>%
  mutate(siteid = as.factor(siteid)) %>% 
  timeAverage(avg.time = "week", type = c("Pollutant", "siteid")) %>% 
  ungroup() %>% 
  filter(!is.na(year))

colston <- sites_weekly %>% 
  filter(siteid == 501) %>%
  ggplot(aes(x = date, y = Concentration, fill = Pollutant)) +
    geom_col(position = "dodge") + 
    scale_y_continuous(quickText("ug m-3")) +
    labs(x = "Date", title = "Changes in weekly mean concentrations by year in lockdown periods: Colston Avenue", caption = "Operational issues 9th April to 16th April 2020") + 
scale_color_brewer(palette = "Dark2") +
         facet_wrap(~ as.factor(year), scales = "free_x") 

# ggsave(here::here("plots", "covid_colston.png"), colston, device = "png", width = 10, height = 6, dpi = 200)
colston +
  theme_report_facet()
```

Other sites on the network show similar patterns. For the [Wells Road](https://opendata.bristol.gov.uk/pages/aqcontinuoussites/?q=siteid:270) site, the difference in concentrations between the two periods was not as pronounced as for Colston Avenue.

```{r data viz Bristol sites, eval = TRUE, echo = FALSE, warning = FALSE, results = "show", fig.height = 7, fig.width = 11, fig.cap = "Fig . NOx and NO2: Wells Road"}

siteplot <- sites_weekly %>% 
   filter(siteid == 270) %>%
  ggplot(aes(x = as.Date(date), y = Concentration, fill = Pollutant)) +
    geom_col(position = "dodge") +
    scale_y_continuous(quickText("ug m-3")) +
    labs(x = "Date", title = "Changes in weekly mean concentrations in lockdown periods: Wells Road") + scale_color_brewer(palette = "Dark2") +
     facet_wrap(~ as.factor(year), scales = "free_x") 

siteplot +
  theme_report_facet() 
  
# ggsave(here::here("plots", "covid_siteplot.png"), siteplot, device = "png", width = 10, height = 6, dpi = 200)

```

## Time variation

Analysis of the time variation of NOx shows a drastic reduction at all hours of the day when compared to the same period in 2019. Again, while this cannot be be attributed solely to the lockdown measures, it is likely that traffic reductions from the lockdown play a significant role.

```{r data viz timeVariation NOx  hide, eval = TRUE, echo = FALSE, results = "show", fig.show = "hide" }

tv_nox <- timeVariation(lockdown_roadside, pollutant = "nox", type = "year", group = "location", ylab = "ugm-3", ci = F, lwd = 4, cols = openColours(scheme = "Dark2"))


```
```{r data viz timeVariation NOx show, eval = TRUE, echo = FALSE, results = "show", fig.height = 7, fig.width = 11, fig.cap = "Fig.  Time Variation of NOx at roadside sites in lockdown period by hour"}
plot(tv_nox, subset = "hour")

# png(filename = here::here("plots", "tv_nox_hour.png"), width = 14, height = 10, res = 200, units = "in")
# plot(tv_nox, subset = "hour")
# dev.off()
```

A similar reduction is shown when plotted by day of the week.
```{r data viz timeVariation NOx show day, eval = TRUE, echo = FALSE, results = "show", , fig.height = 7, fig.width = 11, fig.cap = "Fig . Time Variation of NOx at roadside sites in lockdown period by day"}
plot(tv_nox, subset = "day")
```

For NO~2~ the reduction is less than for NOx, because NO~2~ is not directly proportional to exhaust emissions, but is the result of photochemical reactions with NOx and other gases which happen in a timescale of hours.

```{r data viz timeVariation NO2 hide, eval = TRUE, echo = FALSE, results = "show", fig.show = "hide"}

tv_no2 <- timeVariation(lockdown_roadside, pollutant = "no2", type = "year", group = "location", ylab = "ugm-3", lwd = 3, ci = F, cols = openColours(scheme = "Dark2"))

```

```{r data viz timeVariation NO2 show, eval = TRUE, echo = FALSE, results = "show", , fig.height = 7, fig.width = 11, fig.cap = "Fig . Time Variation of NO2 at roadside sites in lockdown period by hour"}
plot(tv_no2, subset = "hour")
# 
# png(filename = here::here("plots", "tvno2_hour.png"), width = 12, height = 10, res = 200, units = "in")
# plot(tv_no2, subset = "hour")
# dev.off()

```


As explained earlier, PM~10~ reductions are not as significant as NOx or NO~2~ because lockdown measures only affect the locally generated component of PM~10~ and not the regional or secondary components.

```{r data viz timeVariation PM10 hide, eval = TRUE, echo = FALSE, fig.show = "hide"}
 
tv_pm10 <- timeVariation(filter(lockdown, !is.na(pm10)), pollutant = "pm10", type = "year", group = "location",  ylab = "ugm-3", lwd = 3, ci = F, cols = openColours(scheme = "Dark2"))

```

```{r data viz timeVariation PM10 show, eval = TRUE, echo = FALSE, results = "show", fig.height = 7, fig.width = 11, fig.cap = "Fig . Time Variation of PM10 in lockdown period by hour"}
plot(tv_pm10, subset = "hour")
```

## Meteorology

Analysis of the wind speed and direction from [Bristol Lulsgate](https://opendata.bristol.gov.uk/explore/dataset/met-data-bristol-lulsgate/information/) show that although wind speeds from the NE quadrant were higher in the 2020 lockdown period than in the baseline period in 2019, it is unlikely that this can explain all of the dramatic reduction shown as the wind from the dominant direction for this period will be somewhat polluted by other urban upwind emissions. Further de - weathering analysis is required to establish this with more certainty and is summarised in the following section.

```{r data viz Meteorology, eval = TRUE, echo = FALSE, warning = FALSE, results = "show", fig.height = 7, fig.width = 10, fig.cap = "Fig . Wind roses for lockdown periods: Bristol Lulsgate"}
   
windRose(met_data_DT_hr[between(yday(date), lockdown_start_julian, lockdown_end_julian),], ws = "ws", wd = "wd", type = "year", main = "Wind roses for COVID-19 lockdown periods: 2019 and 2020")
```

### De - weathering ambient air quality measurements
The deweather functions of the [openair package](https://cran.r-project.org/web/packages/openair/index.html) were used to remove the effect of the weather on concentrations of regulated pollutant measured by Bristol City Council's and Defra's monitoring sites in Bristol. The deweather package uses a boosted regression tree approach for modelling air quality data. This technique builds a statistical model of the air quality data and thereby takes account of the many complex interactions between variables as well as non-linear relationships between the variables.

Predictions of daily mean concentrations are derived from the modelled hourly means of data that are aggregated by site type. The accepted classifications of "Urban Background" (distant from busy road) and "Urban Traffic" (close to busy road) were used, as well as a classification of "City Centre" to cover the most polluted site, Colston Avenue, as this site represents the most polluted air in the city. Sites with a data capture less than 90% are not used in the analysis. The table below shows the classes for each of the sites analysed.

```{r table sites, eval = TRUE, echo = FALSE, warning = FALSE, message = FALSE, results = "show", fig.height = 7, fig.width = 10, fig.cap = "Fig . Sites aggregated for model analysis"}

classtable <-   aq_met_dw_hourly %>% 
    select(site, dw_group) %>% 
    group_by(site, dw_group) %>% 
    summarise(n=n()) %>% 
    ungroup(site) %>% 
    select(-n) %>% 
  datatable(colnames = c("Site", "Classification"),
            options = list(dom = "t")) # just the table
#figure captions only seem to work for DT::datatables
  
classtable

```

The chart shown below is the predicted "de - weathered" concentrations of three pollutants grouped into site types. The removal of the influence of the weather indicates that the reductions in measurements of traffic pollutants are probably not due solely to the weather. Reductions in traffic emissions due to COVID-19 lockdown measures is the likely explanation.

For NO~2~ it is noticeable that at the city centre site (Colston Avenue) concentrations started to decline around the 16th March, and continued to decline further in the days immediately following lockdown on the 24th March. The post - lockdown decline was also apparent in the urban traffic and urban background site classes. A small increase in NO~2~ at urban traffic and urban background sites was seen around 8th - 12th of April. This could be explained by a regional pollution episode that also increased PM~10~ concentrations during the same period. Unfortunately operational issues at the city centre site mean that data was unavailable from the 9th April to the 15th April.

For NOx, a similar reduction was seen at the city centre site after the 16th April and a small reduction in concentrations at urban traffic sites is apparent.

PM~10~ concentrations did decline in the immediate post - lockdown period but then rose steeply during the pollution episode over Easter weekend. The boosted regression tree models used in the de - weathering process take into account wind speed and direction but cannot account for elevated pollutant levels in the incoming air and hence are unable to remove the effect of regional pollution episodes such as the one that occurred at this time.

```{r deweather model, eval = TRUE, echo = FALSE, warning = FALSE, message = FALSE, results = "hide", fig.show = "hide"}
# 
#set variables for the models
vars = c("trend", "ws", "wd", "hour", "weekday", "temp", "week")
metVars = c("ws", "wd", "hour", "weekday", "temp", "week")

#pivot to enable grouping by pollutant
#keep only pm10 and no2 as model fails with low numbers from pm2.5 and ozone
#group by pollutant and site type, nesting other columns into a list column, data
#apply the testMod, buildMod, and metSim models to each data frame by group
#also create a ggplot object for each de - weathered output and a filename so that they can be 
#iterative plotted

#--------------------------run the deweather model--------------------------------------
if(update){
models_plots <- dw_hourly_agg %>%
  pivot_longer(cols = pm10:pm2.5, names_to = "pollutant", values_to = "concentration") %>%
  filter(pollutant == "pm10" | pollutant == "no2" | pollutant == "nox") %>%
  group_by(dw_group, pollutant) %>%
  nest() %>%
  mutate(testMod = map(data, ~ testMod(., vars = vars, pollutant = "concentration")),
         buildMod = map(data, ~ buildMod(., vars = vars, pollutant = "concentration", n.core = 6, B = 100)),
         demet = map(buildMod, ~ metSim(., metVars = metVars)),
         plot = map(demet, ~ggplot(timeAverage(., "day"), aes(date, pred)) + geom_line(col = "dodgerblue", size = 1) +
    ylab(quickText("ug/m3")) +
    labs(title = quickText(paste0("De - weathered concentrations of ", pollutant, ": ", dw_group)))),
    filename = paste0(dw_group, "_", pollutant, "_", ".png"))

nms <- c("aq_data_DT", "met_data_DT", "aq_monitors", "core_raw", "allsites_meta", "models_plots")

save(aq_data_DT, met_data_DT, aq_monitors, core_raw, allsites_meta, models_plots, file = here::here("data", "covid", "dfs.RData"))

} else {
  
}


#subset the useful columns for plotting
# saveplots <- models_plots %>% 
#   ungroup() %>% 
#   select(filename, plot)
# #iteratively save the ggplots
# pwalk(saveplots, ggsave, path = here::here("plots"))

#extract (unnest) the dataframe of predictions from the deweather model
deweathered_predictions <- models_plots %>% 
  select(dw_group, pollutant, demet) %>% 
  unnest(demet)

```


```{r deweather chart, eval = TRUE, echo = FALSE, warning = FALSE, message = FALSE, results = "show", fig.height = 7, fig.width = 10, fig.show = "show", fig.cap = "Fig . Deweathered chart"}

rdf_P <- rect_df %>% 
  mutate_if(is.Date, as_datetime) 

#and plot
dwp_plot <- deweathered_predictions %>% 
  ungroup() %>% 
  timeAverage(avg.time = "day", type = c("dw_group", "pollutant")) %>% 
  rename(`Site type` = dw_group) %>%
  ungroup() %>% 
  mutate(pollutant = toupper(pollutant)) %>% 
  ggplot(aes(x = date, y = pred, color = `Site type`))  +
  geom_rect(data = rdf_P, mapping = aes(x = NULL, y = NULL, xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, fill = fill), alpha = 0.1, color = "black", lty = "dashed") +
  scale_fill_manual(values = c("#00AFBB", "#FC4E07")) +
  geom_line(lwd = 2) +
  scale_color_brewer(palette = "Dark2") +
  labs(title = "Daily mean de - weathered predictions of pollutant concentrations", subtitle = "Bristol: 2020", caption = "Operational issues at city centre site: April 9th to April 16th", fill = "Period", y = quickText("Predicted concentration ( ugm-3 )"), x = "Date") +
  facet_grid(pollutant ~ ., scales = "free_y") +
  theme_report_facet() +
  easy_plot_legend_size(size = 14) +
  easy_plot_legend_title_size(size = 16) +
  theme(strip.text.y = element_text(color = "black", face = "bold", size = 14, angle = 0))


dwp_plot 

ggsave(dwp_plot, filename = here::here("plots", "deweathered_no2_pm10_plot.png"), device = "png", dpi = 200, width = 12, height = 8)
```


```{r deweather site, eval = TRUE, echo = FALSE, warning = FALSE, message = FALSE, results = "hide", fig.height = 7, fig.width = 10, , fig.show = "hide", fig.cap = "Fig . Deweathered chart"}
calplot_data <- deweathered_predictions %>%
  group_by(dw_group, pollutant) %>% 
  mutate(meanconcs = mean(pred, na.rm = T),
         dev = pred - meanconcs,
         devbin = cut(dev, breaks = c(-120, -20, 20, 100, 200)))

calplot_data %>%
  filter(pollutant == "nox") %>% 
  ggplot(aes(x = date, y = dw_group, fill = devbin)) +
  geom_tile() +
  scale_color_viridis_d()

trendLevel(timeAverage(calplot_data, avg.time = "day", type = "dw_group"),  pollutant = "dev", x = "date", y = "dw_group")
head(mydata)
```

### Cusum charts of NOx
Cusum charts were plotted for sites measuring NOx during March 2020. Cusum charts are used in statistical process control to indicate where a change occurs in a measured variable. In this instance, the difference in daily mean measured concentrations of NOx between the day in 2020 and the mean of the daily values in 2018 and 2019 is plotted. The day is adjusted so that the weekdays are identical to account for the different diurnal variation by weekday.

It can be seen that all sites showed a declining trace from the beginning of March. This is inline with the national picture of declining concentrations of NOx under "business as usual" because of improving engine technology. However, all sites also show an inflection of the trace around the time of the period between the social distancing edict and lockdown proper. There is some evidence that the cusum trace is levelling off towards the end of the analysis period, which is to be expected, as traffic flows stabilise at a minimum or even start to increase.

```{r cusum analysis, eval = TRUE, echo = FALSE, warning = FALSE, message = FALSE, results = "hide", fig.height = 7, fig.width = 10, , fig.show = "show", fig.cap = "Fig . Cusum analysis of Bristol NOx data"}

cusum_plot_data <- 
  aq_data_DT %>% 
  select(date, code = siteid, site = location, nox) %>% 
  timeAverage(avg.time = "day", type = c("code", "site")) %>%
    ungroup() %>% # to get a daily mean - seems adequate
    mutate(year = as.integer(format(date, "%Y")),
           yday = yday(date) + 2018 - year) %>% #shift julian date by one to ensure delta is
    select(-code, -date) %>%                    #like from like, ie monday from monday
    filter(between(yday, studyStartDate_julian, lockdown_end_julian),#study period
           site != "Colston Avenue") %>% #started nov 2018
    pivot_wider(id_cols = c("site", "yday"), names_from = year, values_from = nox, names_prefix = "nox_") %>%
  mutate(d = nox_2020 - rowMeans(select(., nox_2018, nox_2019), na.rm = T)) %>% #needs to be befor grouping
    group_by(site) %>% 
    mutate(delta = ifelse(is.na(d), zoo::na.locf(d), d)) %>% # replace NA with the last valid datapoint in group
            mutate(cumsum_delta = cumsum(delta), #here's the magic
           date = as.Date("2019-12-31") + yday) #recreate a date column for plotting



cusum_plot <- cusum_plot_data %>% 
    ggplot(aes(x = date, y = cumsum_delta)) +
 geom_rect(data = rect_df, mapping = aes(x = NULL, y = NULL, xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, fill = fill), alpha = 0.3, color = "black", lty = "dashed") +
  scale_fill_manual(values = c("#00AFBB", "#FC4E07")) +
  geom_line(lwd = 2, color = "black") +
    # geom_smooth(se = F, lwd = 1, color = "black", method = "loess", formula = 'y ~ x') +
    facet_wrap( ~ site, scales = "free_y") +
  labs(title = "Cumulative sum (cusum) chart of NOx at Bristol sites",
       subtitle = "2020 data compared with mean daily concentrations in 2018 - 2019",
       x = "Date:2020", y = "Cumulative sum of difference in daily NOx",
       fill = "Period") +
  theme_report_facet()

cusum_plot 

```

